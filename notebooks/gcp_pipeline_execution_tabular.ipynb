{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction Pipeline in Vertex AI\n",
    "\n",
    "This notebook demonstrates the deployment of a tabular model for crop yield prediction using Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear pip cache and uninstall existing packages\n",
    "%pip cache purge\n",
    "%pip uninstall -y numpy pandas google-cloud-aiplatform kfp kfp-server-api kfp-pipeline-spec\n",
    "%pip install numpy==1.24.3\n",
    "%pip install pandas==2.1.4\n",
    "%pip install \"kfp==2.6.0\" \n",
    "%pip install \"google-cloud-aiplatform>=1.35.0\"\n",
    "%pip install \"google-cloud-pipeline-components>=2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
    "\n",
    "# Import required packages\n",
    "from kfp import compiler\n",
    "from kfp.dsl import component, Input, Output, Dataset, Artifact,Model,pipeline\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.auth import default\n",
    "from datetime import datetime\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Get default credentials and project\n",
    "credentials, project_id = default()\n",
    "\n",
    "# Configuration\n",
    "REGION = \"us-central1\"\n",
    "bucket_name = \"agrifingcpflow-465809-bucket\"\n",
    "PIPELINE_ROOT = f\"gs://{bucket_name}/pipeline_root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tabular dataset at: gs://agrifingcpflow-465809-bucket/sample_tabular_data/farming_data.csv\n"
     ]
    }
   ],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample tabular dataset for crop yield prediction.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # Create sample tabular data\n",
    "    df = pd.DataFrame({\n",
    "        'field_size': np.random.uniform(1, 100, 100),\n",
    "        'temperature': np.random.normal(25, 5, 100),\n",
    "        'rainfall': np.random.normal(50, 10, 100),\n",
    "        'soil_quality': np.random.choice(['good', 'medium', 'poor'], 100),\n",
    "        'yield': np.random.normal(75, 15, 100)\n",
    "    })\n",
    "    \n",
    "    # Upload to GCS\n",
    "    blob = bucket.blob('sample_tabular_data/farming_data.csv')\n",
    "    blob.upload_from_string(df.to_csv(index=False))\n",
    "    \n",
    "    return f\"gs://{bucket_name}/sample_tabular_data/farming_data.csv\"\n",
    "\n",
    "# Create the sample data and get the URI\n",
    "tabular_uri = create_sample_data()\n",
    "print(f\"Created tabular dataset at: {tabular_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        'google-cloud-storage',\n",
    "        'google-cloud-aiplatform',\n",
    "        'pandas',\n",
    "        'scikit-learn',\n",
    "        'numpy'\n",
    "    ]\n",
    ")\n",
    "def preprocess_data(\n",
    "    tabular_data: str,\n",
    "    bucket_name: str,\n",
    "    project_id: str,\n",
    "    region: str,\n",
    "    tabular_dataset: Output[Dataset]\n",
    "):\n",
    "\n",
    "    \"\"\"Preprocess tabular data for crop yield prediction.\"\"\"\n",
    "    from google.cloud import storage\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import logging\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    logger.info(\"Reading data from: %s\", tabular_data)\n",
    "    df = pd.read_csv(tabular_data)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le = LabelEncoder()\n",
    "    df['soil_quality'] = le.fit_transform(df['soil_quality'])\n",
    "    \n",
    "    # Save processed data\n",
    "    output_uri = f\"gs://{bucket_name}/processed_data/farming_data_processed.csv\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob('processed_data/farming_data_processed.csv')\n",
    "    blob.upload_from_string(df.to_csv(index=False))\n",
    "    \n",
    "    logger.info(\"Saved processed data to: %s\", output_uri)\n",
    "    \n",
    "    # Save to the KFP output location\n",
    "    with open(tabular_dataset.path, 'w') as f:\n",
    "        f.write(output_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform',\n",
    "        'google-cloud-storage'\n",
    "    ]\n",
    ")\n",
    "def train_tabular_model(\n",
    "    project_id: str,\n",
    "    region: str,\n",
    "    dataset: Input[Artifact],\n",
    "    min_accuracy: float,\n",
    "    model_info: Output[Model]\n",
    "):\n",
    "\n",
    "    \"\"\"Train AutoML Tabular model for crop yield prediction.\"\"\"\n",
    "    from google.cloud import aiplatform\n",
    "    import logging\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Initialize Vertex AI\n",
    "    aiplatform.init(project=project_id, location=region)\n",
    "    \n",
    "    logger.info(\"Creating dataset from: %s\", dataset)\n",
    "    \n",
    "    # Create dataset\n",
    "    ai_dataset = aiplatform.TabularDataset.create(\n",
    "        display_name=\"crop_tabular_dataset\",\n",
    "        gcs_source=dataset\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Training AutoML model\")\n",
    "    \n",
    "    # Train model\n",
    "    job = aiplatform.AutoMLTabularTrainingJob(\n",
    "        display_name=\"crop_tabular_model\",\n",
    "        optimization_prediction_type=\"regression\",\n",
    "        optimization_objective=\"minimize-rmse\"\n",
    "    )\n",
    "    \n",
    "    model = job.run(\n",
    "        dataset=ai_dataset,\n",
    "        target_column=\"yield\",\n",
    "        budget_milli_node_hours=1000,  # ~1 hour\n",
    "        model_display_name=\"crop_tabular_model\",\n",
    "        training_fraction_split=0.8,\n",
    "        validation_fraction_split=0.1,\n",
    "        test_fraction_split=0.1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    eval_metrics = model.get_model_evaluation()\n",
    "    rmse = eval_metrics.metrics['rmse']\n",
    "    logger.info(\"Model RMSE: %f\", rmse)\n",
    "    \n",
    "    if rmse > min_accuracy:\n",
    "        raise ValueError(f\"Model RMSE {rmse} above threshold {min_accuracy}\")\n",
    "    \n",
    "    # Save model info\n",
    "    model_info_dict = {\n",
    "        'resource_name': model.resource_name,\n",
    "        'rmse': float(rmse)\n",
    "    }\n",
    "    \n",
    "    with open(model_info.path, 'w') as f:\n",
    "        f.write(model.resource_name)\n",
    "    \n",
    "    return model_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\kfp\\dsl\\component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "@component(\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.104.0'\n",
    "    ]\n",
    ")\n",
    "def deploy_model(\n",
    "    project_id: str,\n",
    "    region: str,\n",
    "    model: Input[Model],\n",
    "    endpoint_info: Output[Artifact]\n",
    "):\n",
    "\n",
    "\n",
    "    \"\"\"Deploy the trained model to an endpoint.\"\"\"\n",
    "    from google.cloud import aiplatform\n",
    "    import logging\n",
    "    import json\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Initialize Vertex AI\n",
    "    aiplatform.init(project=project_id, location=region)\n",
    "    \n",
    "    # Get the model resource name from the artifact\n",
    "    with open(model.path, 'r') as f:\n",
    "        model_resource_name = f.read().strip()\n",
    "    \n",
    "    # Get the model\n",
    "    model = aiplatform.Model(model_resource_name)\n",
    "    \n",
    "    # Deploy the model\n",
    "    endpoint = model.deploy(\n",
    "        machine_type=\"n1-standard-4\",\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=1\n",
    "    )\n",
    "    \n",
    "    endpoint_info_dict = {\n",
    "        'endpoint_name': endpoint.resource_name,\n",
    "        'display_name': endpoint.display_name\n",
    "    }\n",
    "    \n",
    "    # Save endpoint info\n",
    "    with open(endpoint_info.path, 'w') as f:\n",
    "        json.dump(endpoint_info_dict, f)\n",
    "    \n",
    "    return endpoint_info_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name='Crop Yield Prediction Pipeline',\n",
    "    description='Pipeline for agricultural yield prediction using tabular data'\n",
    ")\n",
    "def crop_prediction_pipeline(\n",
    "    project_id: str,\n",
    "    region: str,\n",
    "    bucket_name: str,\n",
    "    tabular_dataset_uri: str,\n",
    "    min_accuracy: float = 0.8\n",
    "):\n",
    "    # Preprocess data\n",
    "    preprocess_task = preprocess_data(\n",
    "        tabular_data=tabular_dataset_uri,\n",
    "        bucket_name=bucket_name,\n",
    "        project_id=project_id,\n",
    "        region=region\n",
    "    )\n",
    "\n",
    "    # Train tabular model\n",
    "    train_tabular_task = train_tabular_model(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        dataset=preprocess_task.outputs['tabular_dataset'],\n",
    "        min_accuracy=min_accuracy\n",
    "    )\n",
    "    train_tabular_task.after(preprocess_task)\n",
    "\n",
    "    # Deploy model\n",
    "    deploy_task = deploy_model(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        model=train_tabular_task.outputs['model_info']\n",
    "    )\n",
    "    deploy_task.after(train_tabular_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Project ID: agrifingcpflow-465809\n",
      "Current Region: us-central1\n",
      "Authenticated as: agrifin-service-account@agrifingcpflow-465809.iam.gserviceaccount.com\n",
      "✅ Storage API access successful\n",
      "Creating PipelineJob\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 You do not have permission to act as service_account: 681123709451-compute@developer.gserviceaccount.com. (or it may not exist).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\grpc\\_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    270\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\grpc\\_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[0;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[0;32m    331\u001b[0m )\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\grpc\\_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\grpc\\_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[1;34m(new_details, request)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\grpc\\_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1192\u001b[0m (\n\u001b[0;32m   1193\u001b[0m     state,\n\u001b[0;32m   1194\u001b[0m     call,\n\u001b[0;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1197\u001b[0m )\n\u001b[1;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\grpc\\_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"You do not have permission to act as service_account: 681123709451-compute@developer.gserviceaccount.com. (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.43.202:443 {grpc_status:3, grpc_message:\"You do not have permission to act as service_account: 681123709451-compute@developer.gserviceaccount.com. (or it may not exist).\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 41\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Create and run pipeline job\u001b[39;00m\n\u001b[0;32m     28\u001b[0m job \u001b[38;5;241m=\u001b[39m pipeline_jobs\u001b[38;5;241m.\u001b[39mPipelineJob(\n\u001b[0;32m     29\u001b[0m     display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrop-yield-prediction-pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     30\u001b[0m     template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpipeline.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     }\n\u001b[0;32m     39\u001b[0m )\n\u001b[1;32m---> 41\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\google\\cloud\\aiplatform\\pipeline_jobs.py:512\u001b[0m, in \u001b[0;36mPipelineJob.submit\u001b[1;34m(self, service_account, network, reserved_ip_ranges, create_request_timeout, experiment, enable_preflight_validations)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted_errors\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipeline_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gca_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_job_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    519\u001b[0m     preflight_validations_error_messages \u001b[38;5;241m=\u001b[39m extract_error_messages(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\google\\cloud\\aiplatform_v1\\services\\pipeline_service\\client.py:1718\u001b[0m, in \u001b[0;36mPipelineServiceClient.create_pipeline_job\u001b[1;34m(self, request, parent, pipeline_job, pipeline_job_id, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m   1717\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m-> 1718\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\charl\\CascadeProjects\\AIVertexStudio\\venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 You do not have permission to act as service_account: 681123709451-compute@developer.gserviceaccount.com. (or it may not exist)."
     ]
    }
   ],
   "source": [
    "# Check GCP setup\n",
    "print(f\"Current Project ID: {project_id}\")\n",
    "print(f\"Current Region: {REGION}\")\n",
    "print(\"Authenticated as:\", credentials.service_account_email if hasattr(credentials, 'service_account_email') else \"User Account\")\n",
    "\n",
    "# Test GCP API access\n",
    "storage_client = storage.Client()\n",
    "try:\n",
    "    buckets = list(storage_client.list_buckets(max_results=1))\n",
    "    print(\"✅ Storage API access successful\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Storage API access failed:\", str(e))\n",
    "\n",
    "# Initialize Vertex AI\n",
    "aiplatform.init(\n",
    "    project=project_id,\n",
    "    location=REGION,\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "# Compile pipeline\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=crop_prediction_pipeline,\n",
    "    package_path='pipeline.yaml'\n",
    ")\n",
    "\n",
    "# Create and run pipeline job\n",
    "job = pipeline_jobs.PipelineJob(\n",
    "    display_name='crop-yield-prediction-pipeline',\n",
    "    template_path='pipeline.yaml',\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        'project_id': project_id,\n",
    "        'region': REGION,\n",
    "        'bucket_name': bucket_name,\n",
    "        'tabular_dataset_uri': tabular_uri,\n",
    "        'min_accuracy': 0.8\n",
    "    }\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
