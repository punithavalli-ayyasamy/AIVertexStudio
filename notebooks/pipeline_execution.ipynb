{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgriAutoML Pipeline Execution\n",
    "\n",
    "This notebook demonstrates how to execute the AgriAutoML pipeline in Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Authentication\n",
    "\n",
    "First, install required packages and set up authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "\n",
    "# Set your project configuration\n",
    "PROJECT_ID = \"your-project-id\"  # Replace with your project ID\n",
    "REGION = \"us-central1\"          # Replace with your desired region\n",
    "BUCKET_NAME = \"your-bucket\"     # Replace with your GCS bucket name\n",
    "\n",
    "# Initialize Vertex AI\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Sample Data\n",
    "\n",
    "Upload sample data to GCS for pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def upload_sample_data():\n",
    "    \"\"\"Upload sample data to GCS bucket\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "    \n",
    "    # Create sample data paths\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    vision_path = f\"data/{timestamp}/vision\"\n",
    "    tabular_path = f\"data/{timestamp}/tabular\"\n",
    "    \n",
    "    # TODO: Replace with your actual data upload logic\n",
    "    # For demonstration, we'll create placeholder files\n",
    "    vision_blob = bucket.blob(f\"{vision_path}/placeholder.txt\")\n",
    "    vision_blob.upload_from_string(\"Vision dataset placeholder\")\n",
    "    \n",
    "    tabular_blob = bucket.blob(f\"{tabular_path}/placeholder.csv\")\n",
    "    tabular_blob.upload_from_string(\"date,crop,yield\\n2025-01-01,corn,150\")\n",
    "    \n",
    "    return f\"gs://{BUCKET_NAME}/{vision_path}\", f\"gs://{BUCKET_NAME}/{tabular_path}\"\n",
    "\n",
    "# Upload sample data\n",
    "vision_uri, tabular_uri = upload_sample_data()\n",
    "print(f\"Vision data URI: {vision_uri}\")\n",
    "print(f\"Tabular data URI: {tabular_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Pipeline parameters\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}/pipeline_root\"\n",
    "PIPELINE_NAME = \"agri-automl-pipeline\"\n",
    "\n",
    "parameter_values = {\n",
    "    'project_id': PROJECT_ID,\n",
    "    'region': REGION,\n",
    "    'bucket_name': BUCKET_NAME,\n",
    "    'vision_dataset_uri': vision_uri,\n",
    "    'tabular_dataset_uri': tabular_uri,\n",
    "    'min_accuracy': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile and Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from pipelines.agri_automl_pipeline import agri_automl_pipeline\n",
    "from kfp.v2 import compiler\n",
    "\n",
    "# Compile the pipeline\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=agri_automl_pipeline,\n",
    "    package_path='agri_automl_pipeline.json'\n",
    ")\n",
    "\n",
    "# Create and run the pipeline job\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=\"agri_automl_pipeline.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values=parameter_values\n",
    ")\n",
    "\n",
    "job.run(sync=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monitor Pipeline Execution\n",
    "\n",
    "After the pipeline starts, you can monitor its progress in the Vertex AI Console or using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def monitor_pipeline(job):\n",
    "    \"\"\"Monitor pipeline execution status\"\"\"\n",
    "    print(f\"Pipeline URL: {job.gca_resource.name}\")\n",
    "    print(f\"State: {job.state}\")\n",
    "    \n",
    "    if job.state == aiplatform.PipelineState.PIPELINE_STATE_SUCCEEDED:\n",
    "        print(\"\\nPipeline completed successfully!\")\n",
    "        # Get the pipeline outputs\n",
    "        outputs = job.outputs\n",
    "        print(\"\\nOutputs:\")\n",
    "        for key, value in outputs.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "    elif job.state == aiplatform.PipelineState.PIPELINE_STATE_FAILED:\n",
    "        print(\"\\nPipeline failed.\")\n",
    "        print(f\"Error: {job.error}\")\n",
    "\n",
    "# Monitor the pipeline\n",
    "monitor_pipeline(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Access Deployed Endpoints\n",
    "\n",
    "After successful pipeline execution, you can access the deployed model endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def list_endpoints():\n",
    "    \"\"\"List all available endpoints\"\"\"\n",
    "    endpoints = aiplatform.Endpoint.list()\n",
    "    print(\"Available endpoints:\")\n",
    "    for endpoint in endpoints:\n",
    "        print(f\"\\nName: {endpoint.display_name}\")\n",
    "        print(f\"Resource name: {endpoint.resource_name}\")\n",
    "        print(f\"Description: {endpoint.description}\")\n",
    "\n",
    "list_endpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Predictions\n",
    "\n",
    "Make test predictions using the deployed endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_yield(endpoint_name, instance):\n",
    "    \"\"\"Make a prediction using deployed endpoint\"\"\"\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name)\n",
    "    prediction = endpoint.predict([instance])\n",
    "    return prediction\n",
    "\n",
    "# Example prediction\n",
    "sample_instance = {\n",
    "    \"location\": \"Iowa\",\n",
    "    \"crop_type\": \"corn\",\n",
    "    \"planting_date\": \"2025-04-15\",\n",
    "    \"field_size\": 5\n",
    "}\n",
    "\n",
    "# Get endpoint names from pipeline outputs\n",
    "tabular_endpoint = job.outputs['deploy-tabular_endpoint']\n",
    "prediction = predict_yield(tabular_endpoint, sample_instance)\n",
    "print(f\"Predicted yield: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}
