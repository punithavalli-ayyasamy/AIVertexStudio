{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgriAutoML Pipeline Execution in Vertex AI\n",
    "\n",
    "This notebook demonstrates how to execute the AgriAutoML pipeline directly in Vertex AI Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform kfp google-cloud-storage pandas pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from google.auth import default\n",
    "from datetime import datetime\n",
    "from kfp import dsl, components, compiler\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "\n",
    "# Get default credentials and project\n",
    "credentials, project_id = default()\n",
    "\n",
    "# Get the absolute path to the components directory\n",
    "COMPONENTS_DIR = os.path.abspath(os.path.join(os.getcwd(), 'components'))\n",
    "\n",
    "# Function to get absolute component path\n",
    "def get_component_path(component_name):\n",
    "    return os.path.join(os.getcwd(), 'components', component_name)\n",
    "\n",
    "# Configuration\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_NAME = \"qwiklabs-gcp-00-ffe6db11d36b-bucket\"\n",
    "PIPELINE_ROOT = f\"gs://{BUCKET_NAME}/pipeline_root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create and upload sample datasets to GCS\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(BUCKET_NAME)\n",
    "    \n",
    "    # Create sample CSV data\n",
    "    sample_csv = \"\"\"date,location,crop_type,field_size,rainfall,temperature,yield\n",
    "2025-01-01,Iowa,corn,5.0,750,25,150\n",
    "2025-01-15,Kansas,wheat,3.5,500,22,120\n",
    "2025-02-01,Nebraska,soybean,4.2,600,24,130\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Upload tabular data\n",
    "    tabular_blob = bucket.blob(f\"data/{timestamp}/crop_data.csv\")\n",
    "    tabular_blob.upload_from_string(sample_csv)\n",
    "    \n",
    "    # Create dummy vision data\n",
    "    vision_blob = bucket.blob(f\"data/{timestamp}/vision_data.txt\")\n",
    "    vision_blob.upload_from_string(\"Dummy vision data for testing\")\n",
    "    \n",
    "    print(f\"Uploaded sample data to: gs://{BUCKET_NAME}/data/{timestamp}/\")\n",
    "    return (\n",
    "        f\"gs://{BUCKET_NAME}/data/{timestamp}/vision_data.txt\",\n",
    "        f\"gs://{BUCKET_NAME}/data/{timestamp}/crop_data.csv\"\n",
    "    )\n",
    "\n",
    "# Create sample datasets\n",
    "vision_uri, tabular_uri = create_sample_data()\n",
    "print(f\"Vision Dataset URI: {vision_uri}\")\n",
    "print(f\"Tabular Dataset URI: {tabular_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load components\n",
    "preprocess_op = components.load_component_from_file(get_component_path('preprocess.py'))\n",
    "train_vision_op = components.load_component_from_file(get_component_path('train_vision.py'))\n",
    "train_tabular_op = components.load_component_from_file(get_component_path('train_tabular.py'))\n",
    "deploy_op = components.load_component_from_file(get_component_path('deploy.py'))\n",
    "\n",
    "# Define pipeline\n",
    "@dsl.pipeline(\n",
    "    name='AgriAutoML Pipeline',\n",
    "    description='End-to-end pipeline for agricultural yield prediction'\n",
    ")\n",
    "def agri_automl_pipeline(\n",
    "    project_id: str,\n",
    "    region: str,\n",
    "    bucket_name: str,\n",
    "    vision_dataset_uri: str,\n",
    "    tabular_dataset_uri: str,\n",
    "    min_accuracy: float = 0.8\n",
    "):\n",
    "    # Preprocess data\n",
    "    preprocess_task = preprocess_op(\n",
    "        vision_data=vision_dataset_uri,\n",
    "        tabular_data=tabular_dataset_uri,\n",
    "        bucket_name=bucket_name\n",
    "    )\n",
    "\n",
    "    # Train vision model\n",
    "    train_vision_task = train_vision_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        dataset=preprocess_task.output['vision_dataset'],\n",
    "        min_accuracy=min_accuracy\n",
    "    )\n",
    "\n",
    "    # Train tabular model\n",
    "    train_tabular_task = train_tabular_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        dataset=preprocess_task.output['tabular_dataset'],\n",
    "        min_accuracy=min_accuracy\n",
    "    )\n",
    "\n",
    "    # Deploy models\n",
    "    deploy_task = deploy_op(\n",
    "        project_id=project_id,\n",
    "        region=region,\n",
    "        vision_model=train_vision_task.output,\n",
    "        tabular_model=train_tabular_task.output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "aiplatform.init(\n",
    "    project=project_id,\n",
    "    location=REGION,\n",
    "    credentials=credentials\n",
    ")\n",
    "\n",
    "\n",
    "# Compile pipeline\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=agri_automl_pipeline,\n",
    "    package_path='pipeline.yaml'\n",
    ")\n",
    "\n",
    "\n",
    "# Create and run pipeline job\n",
    "job = pipeline_jobs.PipelineJob(\n",
    "    display_name='agri-automl-pipeline',\n",
    "    template_path='pipeline.yaml',\n",
    "    pipeline_root=PIPELINE_ROOT\n",
    "    parameter_values={\n",
    "        'project_id': project_id,  # Changed from PROJECT_ID\n",
    "        'region': REGION,\n",
    "        'bucket_name': BUCKET_NAME,\n",
    "        'vision_dataset_uri': vision_uri,  # Changed from VISION_DATASET_URI\n",
    "        'tabular_dataset_uri': tabular_uri,  # Changed from TABULAR_DATASET_URI\n",
    "        'min_accuracy': 0.8\n",
    "    }\n",
    ")\n",
    "\n",
    "job.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
