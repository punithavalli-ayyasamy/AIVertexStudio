name: train_vision
description: Train AutoML Vision model for crop analysis

inputs:
- {name: project_id, type: String, description: 'GCP project ID'}
- {name: region, type: String, description: 'GCP region'}
- {name: dataset, type: String, description: 'URI of the processed vision dataset'}
- {name: min_accuracy, type: Float, description: 'Minimum required accuracy'}

outputs:
- {name: model_info, type: Dict, description: 'Model information including resource name and metrics'}

implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |
      python3 -m pip install --quiet google-cloud-aiplatform pandas numpy pillow
      python3 -c
    - |
      import sys
      import argparse
      from google.cloud import aiplatform

      parser = argparse.ArgumentParser()
      parser.add_argument('--project_id')
      parser.add_argument('--region')
      parser.add_argument('--dataset')
      parser.add_argument('--min_accuracy', type=float)
      args = parser.parse_args()

      # Initialize Vertex AI
      aiplatform.init(project=args.project_id, location=args.region)

      # Create dataset
      ai_dataset = aiplatform.ImageDataset.create(
          display_name="crop_vision_dataset",
          gcs_source=args.dataset,
          import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification
      )

      # Train model
      job = aiplatform.AutoMLImageTrainingJob(
          display_name="crop_vision_model",
          prediction_type="image_classification"
      )

      ai_model = job.run(
          dataset=ai_dataset,
          target_column="yield",
          budget_milli_node_hours=83.33,  # 5 minutes
          model_display_name="crop_vision_model",
          training_fraction_split=0.8,
          validation_fraction_split=0.1,
          test_fraction_split=0.1
      )

      # Evaluate model
      eval_metrics = ai_model.get_model_evaluation()
      if eval_metrics.metrics['auRoc'] < args.min_accuracy:
          raise ValueError(f"Model accuracy {eval_metrics.metrics['auRoc']} below threshold {args.min_accuracy}")

      # Print output as JSON for KFP
      import json
      model_info = {
          'model': ai_model.resource_name,
          'accuracy': float(eval_metrics.metrics['auRoc'])
      }
      print(json.dumps(model_info))
    args:
    - --project_id
    - {inputValue: project_id}
    - --region
    - {inputValue: region}
    - --dataset
    - {inputValue: dataset}
    - --min_accuracy
    - {inputValue: min_accuracy}
